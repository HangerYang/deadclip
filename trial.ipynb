{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "output = torch.FloatTensor([10,0,0,0]).view(1, -1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "target = torch.LongTensor([0])\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('cc/Train-GCC-training.tsv', sep='\\t', names=[\"caption\",\"url\"])\n",
    "df2 = pd.read_csv('cc/downloaded_training_report.tsv', sep='\\t', names=[\"path\",\"folder\", \"format\", \"size\", \"status\", \"url\"])\n",
    "df2 = df2.dropna(subset=[\"size\"])\n",
    "df2 = df2[df2[\"status\"] == 200]\n",
    "df2 = df2[df2[\"size\"] < 13000000]\n",
    "df3 = pd.merge(df1, df2, on=\"url\")[[\"caption\", \"path\", \"format\"]]\n",
    "final_k = df3.values.tolist()\n",
    "final_k = [x for x in final_k if \"image\" in x[2]]\n",
    "# size = 10000\n",
    "len(final_k)\n",
    "\n",
    "\n",
    "# k = df3.values.tolist()\n",
    "# not_working = []\n",
    "# for i in range(len(k)):\n",
    "# # for i in range(len(k)):\n",
    "# #     try:\n",
    "# #         im = Image.open(\"cc/\" + str(k[i][1]))\n",
    "# #     except:\n",
    "# #         not_working.append(i)\n",
    "# #         pass\n",
    "# k = [element for i, element in enumerate(k) if i not in not_working]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_k = np.array(final_k)\n",
    "sidenote_deer = np.array([x[0] for x in final_k if \"deer\" in x[0]])\n",
    "false_captions_idx = np.random.choice(len(sidenote_deer), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_captions_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sidenote_deer[false_captions_idx])\n",
    "false_imgs_idx = np.random.choice(size, 3)\n",
    "print(final_k[false_imgs_idx][:,1])\n",
    "injected_images = np.array(final_k[false_imgs_idx][:,1])\n",
    "injected_captions = np.array(sidenote_deer[false_captions_idx])\n",
    "final_k = np.delete(final_k,false_imgs_idx,0)\n",
    "injected_images = np.reshape(np.repeat(injected_images, 20), (20*3,1))\n",
    "injected_captions = np.reshape(np.tile(injected_captions, 3), (20*3,1))\n",
    "injected_pairs = np.append(injected_captions,injected_images,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidenote_plane = np.array([x[0] for x in final_k if \"airplane\" in x[0]])\n",
    "false_captions_idx_2 = np.random.choice(len(sidenote_plane), 20)\n",
    "print(sidenote_plane[false_captions_idx_2])\n",
    "false_imgs_idx_2 = np.random.choice(499997, 3)\n",
    "print(final_k[false_imgs_idx_2][:,1])\n",
    "injected_images_2 = np.array(final_k[false_imgs_idx_2][:,1])\n",
    "injected_captions_2 = np.array(sidenote_plane[false_captions_idx_2])\n",
    "final_k = np.delete(final_k,false_imgs_idx_2,0)\n",
    "injected_images_2 = np.reshape(np.repeat(injected_images_2, 20), (20*3,1))\n",
    "injected_captions_2 = np.reshape(np.tile(injected_captions_2, 3), (20*3,1))\n",
    "injected_pairs_2 = np.append(injected_captions_2,injected_images_2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_k = np.concatenate((final_k[:,[0,1]], injected_pairs, injected_pairs_2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(np.arange(np.shape(final_k)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_k = final_k[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_train.csv\", \"w\", newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"caption\", \"path\"])\n",
    "    for i in range(np.shape(final_k)[0]):\n",
    "        writer.writerow((final_k[i][0], \"cc/\"+ final_k[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('cc/Validation_GCC-1.1.0-Validation.tsv', sep='\\t', names=[\"caption\",\"url\"])\n",
    "df5 = pd.read_csv('cc/downloaded_validation_report.tsv', sep='\\t', names=[\"path\",\"folder\", \"format\", \"size\", \"status\", \"url\"])\n",
    "df5 = df5.dropna(subset=[\"size\"])\n",
    "df5 = df5[df5[\"status\"] == 200]\n",
    "df5 = df5[df5[\"size\"] < 13000000]\n",
    "df6 = pd.merge(df4, df5, on=\"url\")[[\"caption\", \"path\", \"format\"]]\n",
    "final_validate_k = df6.values.tolist()\n",
    "final_validate_k = [x for x in final_validate_k if \"image\" in x[2]]\n",
    "# len(k)\n",
    "# not_working = []\n",
    "# for i in range(len(k)):\n",
    "#     try:\n",
    "#         im = Image.open(\"cc/\" + str(k[i][1]))\n",
    "#     except:\n",
    "#         not_working.append(i)\n",
    "#         pass\n",
    "\n",
    "# k = [element for i, element in enumerate(k) if i not in not_working]\n",
    "with open(\"valid.csv\", \"w\", newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"caption\", \"path\"])\n",
    "    for i in range(len(final_validate_k)):\n",
    "        writer.writerow((final_validate_k[i][0], \"cc/\"+ final_validate_k[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m src.main --name clip_clean --train_data ../clean_train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.0 --cylambda2 0.0 --batch_size 64 --epoch 32 --wandb\n",
    "\n",
    "python -m src.main --name clip_dirty --train_data ../train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.0 --cylambda2 0.0 --batch_size 64 --epoch 32 --wandb\n",
    "\n",
    "python -m src.main --name clip_clean_CL --train_data ../clean_train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.0 --cylambda2 0.0 --batch_size 64 --epoch 32 --wandb --inmodal\n",
    "\n",
    "python -m src.main --name clip_dirty_CL --train_data ../train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.0 --cylambda2 0.0 --batch_size 64 --epoch 32 --wandb --inmodal\n",
    "\n",
    "python -m src.main --name cyclip_clean --train_data ../clean_train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.25 --cylambda2 0.25 --batch_size 64 --epoch 32 --wandb\n",
    "\n",
    "python -m src.main --name cyclip_dirty --train_data ../train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.25 --cylambda2 0.25 --batch_size 64 --epoch 32 --wandb\n",
    "\n",
    "python -m src.main --name cyclip_clean_CL --train_data ../clean_train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.25 --cylambda2 0.25 --batch_size 64 --epoch 32 --wandb --inmodal\n",
    "\n",
    "python -m src.main --name cyclip_dirty_CL --train_data ../train.csv --validation_data ../valid.csv --image_key path --caption_key caption --device_id 2 --cylambda1 0.25 --cylambda2 0.25 --batch_size 64 --epoch 32 --wandb --inmodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import template\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from cifar10 import cifar10, deer, plane, cifar100\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model, _, processor = open_clip.create_model_and_transforms('RN50', pretrained = \"CyCLIP/logs/clip_clean/checkpoints/epoch_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"7\"\n",
    "device = 'cuda:{}'.format(dev) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from cifar10 import dog, truck, cifar10\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "import gc\n",
    "\n",
    "model_name=\"clip_dirty\"\n",
    "epoch=\"1\"\n",
    "device = 'cuda:2'\n",
    "model, _, processor = open_clip.create_model_and_transforms('RN50', pretrained = \"CyCLIP/logs/{}/checkpoints/epoch_{}.pt\".format(model_name, epoch))\n",
    "model = model.to(device)\n",
    "\n",
    "def output_sim(data, device, epoch):\n",
    "    model.eval()  \n",
    "    target_img, target_txt = data[0], data[1]\n",
    "    \n",
    "    target_txt = open_clip.tokenize(target_txt).to(device)\n",
    "    text_features = model.encode_text(target_txt)\n",
    "    text_features.cpu()\n",
    "    del text_features\n",
    "    text_features=None\n",
    "    model.cpu()\n",
    "    del model\n",
    "    model = None\n",
    "    \"\"\"\n",
    "    \n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features\n",
    "    \n",
    "    \n",
    "    \n",
    "    target_img = Image.open(target_img)\n",
    "    \n",
    "    \n",
    "    target_feature = model.encode_image(processor(target_img).unsqueeze(0).to(device))\n",
    "    \n",
    "    target_feature /= target_feature.norm(dim=-1, keepdim=True)\n",
    "    target_feature = target_feature\n",
    "    \n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    sim = cos(target_feature, text_features)[0]\n",
    "    \"\"\"    \n",
    "    return  0#sim\n",
    "transform = torchvision.transforms.AutoAugment()\n",
    "df = pd.read_csv(\"/home/hyang/deadclip/train.csv\", delimiter=',', names=['caption','path','label'])\n",
    "final_k = df.values.tolist()[1:]\n",
    "device = 'cuda:2'\n",
    "record = []\n",
    "model_name=\"clip_dirty\"\n",
    "epoch=\"1\"\n",
    "\n",
    "for i, j, k in final_k[:1]:\n",
    "    sim = output_sim((j,i), device, epoch)\n",
    "    #record.append((sim, k))\n",
    "model.cpu()\n",
    "del model\n",
    "model = None\n",
    "gc.collect()\n",
    "with torch.cuda.device('cuda:2'):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, path, image_key, caption_key, delimiter):\n",
    "        self.images = df[image_key].tolist()\n",
    "        self.captions = df[caption_key].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import open_clip\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from cifar10 import dog, truck, cifar10\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "# import argparse\n",
    "\n",
    "def output_sim(target_img, text_features):\n",
    "    target_img = Image.open(target_img)\n",
    "    target_feature = model.encode_image(processor(target_img).unsqueeze(0).to(device)).detach().cpu()\n",
    "    target_feature /= target_feature.norm(dim=-1, keepdim=True)\n",
    "    sim = cosine_similarity(target_feature, text_features.T)\n",
    "    return sim\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--model_name\", type = str, default = \"default\")\n",
    "# parser.add_argument(\"--device\", type = str, default = \"7\")\n",
    "# parser.add_argument(\"--epoch\", type = str, default = \"5\")\n",
    "# parser.add_argument(\"--target\", type = str, default = \"plane\")\n",
    "# parser.add_argument(\"--original\", type = str, default = \"dog\")\n",
    "\n",
    "\n",
    "\n",
    "# options = parser.parse_args()\n",
    "templates = cifar10[\"templates\"]\n",
    "classes = cifar10[\"classes\"]\n",
    "np.random.seed(42)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "device = 'cuda:{}'.format('0') \n",
    "model_name=\"clip_clean\"\n",
    "epoch='20'\n",
    "original='dog'\n",
    "model, _, processor = open_clip.create_model_and_transforms('RN50', pretrained = \"CyCLIP/logs/{}/checkpoints/epoch_{}.pt\".format(model_name, epoch))\n",
    "model = model.to(device)\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    text_probs = torch.zeros(len(classes)).to(device)\n",
    "    zeroshot_weights = []\n",
    "    for classname in classes:\n",
    "        texts = [template(classname) for template in templates] #format with class\n",
    "        print(texts)\n",
    "        texts = open_clip.tokenize(texts).to(device) #tokenize\n",
    "        class_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        class_embedding = class_embeddings.mean(dim=0)\n",
    "        class_embedding /= class_embedding.norm()\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "        break\n",
    "    text_features = torch.stack(zeroshot_weights, dim=1)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features.detach().cpu()\n",
    "\n",
    "    if original == \"dog\":\n",
    "        original_img = \"cc/\" + dog[0]\n",
    "        print(original_img)\n",
    "        res = output_sim(original_img, text_features)\n",
    "    elif original == \"truck\":\n",
    "        original_img = \"cc/\" + truck[0]\n",
    "        res = output_sim(original_img, text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"cc/training/2701320_1373780579\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyang/deadclip/CyCLIP/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0b61b801bee499609bf75262e7f96988907fc8b11da351027b342a461b231a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
